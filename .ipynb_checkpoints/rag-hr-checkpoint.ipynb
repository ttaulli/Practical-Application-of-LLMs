{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354b81c4-0d74-4302-8df0-a113b5a3ab8a",
   "metadata": {},
   "source": [
    "# RAG + HR Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae13eb3-e31c-416a-91fe-3da01c836c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain-openai\n",
    "# !pip install langchain-community\n",
    "# !pip install chromadb\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ba3527-aa9c-438c-91d4-e7237fe0f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7436e70e-456d-44f7-9338-1a0a9a318f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Missing OPENAI_API_KEY in environment\")\n",
    "\n",
    "llm = ChatOpenAI(api_key=api_key, model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64de20c-765d-4e05-9928-de5d55e62507",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"hr_policy_long.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed7b68d-126b-4787-a3a7-f0e4a3978ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1c6da6-c3eb-4279-b2a6-cf8689d85360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks created: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad0f4593-e937-4817-9bfe-eea2667b68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(api_key=api_key)\n",
    "vectordb = Chroma.from_documents(split_docs, embeddings, persist_directory=\"./hr_chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099d0a5b-4016-4018-9e5b-36c4db7d7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "057bc3dc-a672-4d07-b65d-f5b3dcc72c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are an HR assistant. Use the following HR policy context to answer the question at the end.\n",
    "If the answer is not in the document, respond with 'I don't know.'\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9432c290-dcd1-45a8-bc21-cf97c63aaf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b36bec92-4068-459d-8b55-3317370945aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How many sick days do employees get each year?\n",
      "A: {'query': 'How many sick days do employees get each year?', 'result': 'Employees receive 5 sick days per year.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the company policy on overtime pay?\"\n",
    "response = qa_chain.invoke(query)\n",
    "\n",
    "\n",
    "print(\"Q:\", query)\n",
    "print(\"A:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162531e7-34d4-41da-8ad4-c9ccae42cbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
